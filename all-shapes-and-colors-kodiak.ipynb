{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11288817,"sourceType":"datasetVersion","datasetId":7058528}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport ast # used to convert label column into python tuples\nfrom itertools import chain # tool to create chains of text\nfrom sklearn.preprocessing import MultiLabelBinarizer # used to binarize labels for easier processing\nimport torch.nn as nn # classes to help buld neural nets\nimport torch.nn.functional as F # gives stateless version of activation functions and nn layers\nimport cv2 \nfrom matplotlib import pyplot as plt\nfrom IPython.display import display\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\n\ndf = pd.read_csv('/kaggle/input/all-shapes-and-colors/train_v2.csv')\n\ndf['label'] = df['label'].apply(ast.literal_eval) # convert label to tuples safely\n\n# create set of all labels\nlabel_set = set(chain.from_iterable(df['label']))\n\n# binarize lables and put into dataframe (multi-hot vector of classes)\nmlb = MultiLabelBinarizer()\nlabels_binarized = mlb.fit_transform(df['label'])\nlabels_df = pd.DataFrame(labels_binarized, columns=mlb.classes_)\ndf = pd.concat([df, labels_df], axis=1)\n\nprint(df)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:32:24.573536Z","iopub.execute_input":"2025-04-06T03:32:24.573790Z","iopub.status.idle":"2025-04-06T03:32:30.624864Z","shell.execute_reply.started":"2025-04-06T03:32:24.573771Z","shell.execute_reply":"2025-04-06T03:32:30.624074Z"}},"outputs":[{"name":"stdout","text":"                         image_path  \\\n0        train_dataset_v2/img_0.png   \n1        train_dataset_v2/img_1.png   \n2        train_dataset_v2/img_2.png   \n3        train_dataset_v2/img_3.png   \n4        train_dataset_v2/img_4.png   \n...                             ...   \n4995  train_dataset_v2/img_4995.png   \n4996  train_dataset_v2/img_4996.png   \n4997  train_dataset_v2/img_4997.png   \n4998  train_dataset_v2/img_4998.png   \n4999  train_dataset_v2/img_4999.png   \n\n                                                  label  (circle, blue)  \\\n0                                     [(square, green)]               0   \n1                                                    []               0   \n2                                                    []               0   \n3     [(square, red), (circle, blue), (triangle, gre...               1   \n4                                                    []               0   \n...                                                 ...             ...   \n4995  [(circle, red), (circle, green), (triangle, red)]               0   \n4996               [(triangle, red), (triangle, green)]               0   \n4997  [(triangle, blue), (circle, red), (square, gre...               0   \n4998  [(circle, red), (triangle, green), (square, re...               1   \n4999  [(square, green), (triangle, blue), (circle, g...               0   \n\n      (circle, green)  (circle, red)  (square, blue)  (square, green)  \\\n0                   0              0               0                1   \n1                   0              0               0                0   \n2                   0              0               0                0   \n3                   0              0               0                1   \n4                   0              0               0                0   \n...               ...            ...             ...              ...   \n4995                1              1               0                0   \n4996                0              0               0                0   \n4997                0              1               0                1   \n4998                0              1               0                0   \n4999                1              0               0                1   \n\n      (square, red)  (triangle, blue)  (triangle, green)  (triangle, red)  \n0                 0                 0                  0                0  \n1                 0                 0                  0                0  \n2                 0                 0                  0                0  \n3                 1                 0                  1                0  \n4                 0                 0                  0                0  \n...             ...               ...                ...              ...  \n4995              0                 0                  0                1  \n4996              0                 0                  1                1  \n4997              0                 1                  0                0  \n4998              1                 0                  1                0  \n4999              0                 1                  0                0  \n\n[5000 rows x 11 columns]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# output will have N(6) neurones, one for each color-shape combo\n# rgb & circle square only?\n\n# use sigmoid activation function -> doesnt have to add up to 1 so allows for multiple classes to pass through better\n\nclass CNN(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__() # make sure nn.module is initialized\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc = nn.Linear(32 * 16 * 16, num_classes)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))  # → (16, 32, 32)\n        x = self.pool(F.relu(self.conv2(x)))  # → (32, 16, 16)\n        x = x.view(x.size(0), -1)             # Flatten\n        x = self.fc(x)       # output?\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:33:01.908254Z","iopub.execute_input":"2025-04-06T03:33:01.908517Z","iopub.status.idle":"2025-04-06T03:33:01.913921Z","shell.execute_reply.started":"2025-04-06T03:33:01.908497Z","shell.execute_reply":"2025-04-06T03:33:01.912818Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# custom dataset that helps load images from the csv\nclass ShapeColorDataset(Dataset):\n    def __init__(self, df, image_root, class_names, transform=None):\n        self.df = df\n        self.image_root = image_root\n        self.class_names = class_names\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    # a special type of pythonn function that tells the object how to behave when accessed with []\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = cv2.imread(f\"{self.image_root}/{row['image_path']}\")\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        if self.transform:\n            img = self.transform(img)\n\n        label = torch.tensor(row[self.class_names].values.astype(np.float32)) # might already be doing thi multi hot conversion\n        return img, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:35:30.748469Z","iopub.execute_input":"2025-04-06T03:35:30.748744Z","iopub.status.idle":"2025-04-06T03:35:30.753185Z","shell.execute_reply.started":"2025-04-06T03:35:30.748724Z","shell.execute_reply":"2025-04-06T03:35:30.752523Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# define transforms \ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((64,64)),\n    transforms.ToTensor(),\n])\n\ndataset = ShapeColorDataset(df, image_root='/kaggle/input/all-shapes-and-colors/dataset_v2/train_dataset_v2', class_names=mlb.classes_, transform=transform)\ndataloader = DataLoader(dataset, barch_size=32, shuffle=True) # idk\n\n# create model, loss and optimizer\nmodel = CNN(num_classes=len(mlb.classes_)) # makes class outputs modular\ncriterion = nn.BCEWithLogitsLoss() # write some stuff about why\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T03:36:40.046891Z","iopub.execute_input":"2025-04-06T03:36:40.047186Z","iopub.status.idle":"2025-04-06T03:36:40.060665Z","shell.execute_reply.started":"2025-04-06T03:36:40.047165Z","shell.execute_reply":"2025-04-06T03:36:40.059560Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-ca5c09c446e0>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShapeColorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/kaggle/input/all-shapes-and-colors/dataset_v2/train_dataset_v2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbarch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# idk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# create model, loss and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"],"ename":"NameError","evalue":"name 'DataLoader' is not defined","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"model.train() # where is this func\nfor epoch in range(5):\n    for images, labels in dataloader:\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n    print(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}